ctit088
	Adding nVidia Cuda Toolkit 10.1
Gpu devices                 : 3
Starting worker: 
/tmp/slurmd/job219550/slurm_script: line 20: ./gpu_burn: No such file or directory
Train Set:  160
Validation Set:  40
Test Set:  100
cuda:1
Traceback (most recent call last):
  File "/home/s3075451/DLMIA/DLMIA-UNet/main.py", line 58, in <module>
    dim=3).to(device)
           ^^^^^^^^^^
  File "/home/s3075451/.conda/envs/DLMIA/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1145, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/s3075451/.conda/envs/DLMIA/lib/python3.11/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/s3075451/.conda/envs/DLMIA/lib/python3.11/site-packages/torch/nn/modules/module.py", line 820, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/home/s3075451/.conda/envs/DLMIA/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

